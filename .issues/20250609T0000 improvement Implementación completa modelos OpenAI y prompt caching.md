√âpica: WIZARD - [2] DISE√ëO DE HISTORIA
Categor√≠a: improvement/*
Notas para devs: Implementaci√≥n completada del soporte completo de modelos OpenAI y prompt caching

Archivos afectados:
- /home/customware/lacuenteria/Lacuenteria/src/types/index.ts
- /home/customware/lacuenteria/Lacuenteria/src/components/UI/ModelBadge.tsx (nuevo)
- /home/customware/lacuenteria/Lacuenteria/src/utils/modelHelpers.ts (nuevo)
- /home/customware/lacuenteria/Lacuenteria/src/components/Prompts/PromptAccordion.tsx
- /home/customware/lacuenteria/Lacuenteria/src/components/Prompts/PromptForm.tsx
- /home/customware/lacuenteria/Lacuenteria/src/components/Admin/PromptEditor.tsx
- /home/customware/lacuenteria/Lacuenteria/src/constants/promptMetadata.ts
- /home/customware/lacuenteria/Lacuenteria/supabase/functions/generate-story/index.ts

üß† Contexto:
Se implement√≥ el soporte completo para todos los modelos de OpenAI actuales, incluyendo GPT-4.1 nano, GPT-4.5 preview, serie O, modelos de audio y legacy. Tambi√©n se optimiz√≥ la generaci√≥n de historias con prompt caching para reducir latencia y costos.

üìê Objetivo:
- Permitir el uso de todos los modelos actuales de OpenAI en el sistema
- Mejorar la experiencia de selecci√≥n de modelos con badges visuales
- Implementar prompt caching para optimizar rendimiento y costos
- Mantener compatibilidad con el sistema existente

‚úÖ CRITERIOS DE √âXITO (lo que s√≠ debe ocurrir):
- El tipo OpenAIModel incluye todos los modelos del cat√°logo
- Los componentes de selecci√≥n muestran badges de tipo de modelo
- Los modelos se filtran correctamente seg√∫n el tipo de prompt
- Los endpoints se actualizan din√°micamente seg√∫n el modelo
- La funci√≥n generate-story incluye el par√°metro user para prompt caching
- Los valores por defecto usan modelos modernos (gpt-4o para texto, gpt-image-1 para imagen)
- El build del proyecto se completa sin errores

‚ùå CRITERIOS DE FALLA (lo que no debe ocurrir):
- No se mezclan modelos de texto en prompts de imagen
- No aparecen errores en consola al seleccionar modelos
- No se pierden configuraciones existentes
- No se rompe la compatibilidad con prompts guardados

üß™ QA / Casos de prueba esperados:
- Crear un nuevo prompt de texto ‚Üí debe mostrar solo modelos de texto
- Crear un prompt de imagen ‚Üí debe mostrar solo modelos de imagen
- Seleccionar un modelo legacy ‚Üí debe mostrar endpoint /v1/completions
- Editar un prompt existente ‚Üí debe mantener modelo y endpoint
- Generar una historia ‚Üí debe usar el par√°metro user en la llamada API

EXTRAS:
- Los modelos legacy (davinci-002, babbage-002) usan el endpoint /v1/completions
- Los modelos de audio tienen endpoints especializados (/v1/audio/speech, /v1/realtime)
- El prompt caching se activa autom√°ticamente para prompts > 1024 tokens
- Se recomienda estructurar prompts con contenido est√°tico al inicio
- Se mantiene gpt-image-1 como modelo de imagen por defecto para compatibilidad
